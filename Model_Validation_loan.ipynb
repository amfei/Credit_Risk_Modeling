{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPIq8Kh2kQGKnf71I6W0KtF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amfei/Credit_Risk_Modeling/blob/main/Model_Validation_loan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, confusion_matrix, classification_report, precision_recall_curve\n",
        "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import logging\n",
        "import xgboost as xgb\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Load the dataset\n",
        "def load_data(filepath):\n",
        "    try:\n",
        "        data = pd.read_csv(filepath)\n",
        "        data.dropna(inplace=True)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading data: {e}\")\n",
        "        raise\n",
        "\n",
        "# Data preprocessing\n",
        "def preprocess_data(data, feature_names):\n",
        "    X = data[feature_names]\n",
        "    y = data['loan_status']\n",
        "    X_input= OHE (X)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_input)\n",
        "    return X_scaled, y, scaler\n",
        "\n",
        "# Model training\n",
        "def train_model(X_train, y_train):\n",
        "    #model= xgb.XGBClassifier(scale_pos_weight=4, max_delta_step= 1,subsample= 0.8,colsample_bytree= 0.8,eval_metric= 'auc')\n",
        "\n",
        "    model = LogisticRegression(random_state=42)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Model evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "    print(f'Test AUC Score: {auc_score}')\n",
        "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "    print(f'Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}')\n",
        "    print(f'Classification Report:\\n {classification_report(y_test, y_pred)}')\n",
        "\n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "    print(f'Cross-Validation AUC Scores: {cv_scores}')\n",
        "    print(f'Average Cross-Validation AUC Score: {np.mean(cv_scores)}')\n",
        "\n",
        "    return y_pred_proba, y_pred\n",
        "\n",
        "\n",
        "# ROC Curve\n",
        "def plot_roc_curve(y_test, y_pred_proba):\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# Calibration Plot\n",
        "def plot_calibration_curve(y_test, y_pred_proba):\n",
        "    prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label='Logistic Regression')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
        "    plt.xlabel('Predicted probability')\n",
        "    plt.ylabel('True probability')\n",
        "    plt.title('Calibration plot: how well model predicted probabilities reflect the actual outcomes')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Lift Chart\n",
        "def plot_lift_chart(y_test, y_pred_proba, n_bins=10):\n",
        "    data = pd.DataFrame({'y_true': y_test, 'y_prob': y_pred_proba})\n",
        "    data['bin'] = pd.qcut(data['y_prob'], n_bins, duplicates='drop')\n",
        "    lift_df = data.groupby('bin').agg({'y_true': ['sum', 'count']})\n",
        "    lift_df.columns = ['sum', 'count']\n",
        "    lift_df['lift'] = lift_df['sum'] / (lift_df['count'] * (data['y_true'].sum() / len(data)))\n",
        "    lift_df = lift_df.sort_index(ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(lift_df['lift'].values, marker='o', linestyle='--')\n",
        "    plt.xlabel('Decile')\n",
        "    plt.ylabel('Lift')\n",
        "    plt.title('Lift Chart: ratio of the actual number of defaults in the decile to the expected number of defaults')\n",
        "    plt.xticks(range(n_bins), [f'Decile {i+1}' for i in range(n_bins)])\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Assumption Checking: Multicollinearity\n",
        "def plot_correlation_matrix(X_scaled, feature_names):\n",
        "    cor_matrix = pd.DataFrame(X_scaled, columns=feature_names).corr()\n",
        "    sns.heatmap(cor_matrix, annot=True, cmap='coolwarm')\n",
        "    plt.title('Feature Correlation Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Sensitivity Analysis\n",
        "def sensitivity_analysis(model, data, scaler, feature_names):\n",
        "    for feature in feature_names:\n",
        "        feature_range = np.linspace(data[feature].min(), data[feature].max(), 100)\n",
        "        temp_df = pd.DataFrame({\n",
        "            #'person_age': data['person_age'].mean(),\n",
        "            'person_emp_length': data['person_emp_length'].mean(),\n",
        "            'loan_int_rate': data['loan_int_rate'].mean(),\n",
        "            'loan_percent_income': data['loan_percent_income'].mean(),\n",
        "            'cb_person_cred_hist_length': data['cb_person_cred_hist_length'].mean()\n",
        "        }, index=range(100))\n",
        "        temp_df[feature] = feature_range\n",
        "        temp_df_scaled = scaler.transform(temp_df)\n",
        "        sensitivity_pred_proba = model.predict_proba(temp_df_scaled)[:, 1]\n",
        "\n",
        "        plt.figure(figsize=(7, 5))\n",
        "        plt.plot(feature_range, sensitivity_pred_proba, label=f'Predicted default probability')\n",
        "        plt.xlabel(feature)\n",
        "        plt.ylabel('Predicted Default Probability')\n",
        "        plt.title(f'Sensitivity Analysis: Effect of {feature} on Default Probability')\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def countplot(data):\n",
        "\n",
        "  # count plot on single categorical variable\n",
        "  sns.countplot(data)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "def plot_precision_recall_curve(y_test, y_pred_proba):\n",
        "  precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "  plt.figure(figsize = (6,6))\n",
        "  plt.plot([0, 1], [0.5, 0.5],'k--')\n",
        "  plt.plot(recall, precision)\n",
        "  plt.xlabel('recall')\n",
        "  plt.ylabel('precision')\n",
        "  plt.title('Precision-Recall Curve (PRC)')\n",
        "  plt.show()\n",
        "\n",
        "def calc_vif(X):\n",
        "\n",
        "  # Calculating VIF\n",
        "  vif = pd.DataFrame()\n",
        "  vif[\"variables\"] = X.columns\n",
        "  vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "  print(vif)\n",
        "  return vif\n",
        "\n",
        "\n",
        "def OHE(X):\n",
        "    # Ensure categorical columns are treated as strings\n",
        "    X.loc[:, 'person_home_ownership'] = X['person_home_ownership'].astype(str)\n",
        "    X.loc[:, 'loan_intent'] = X['loan_intent'].astype(str)\n",
        "    X.loc[:, 'loan_grade'] = X['loan_grade'].astype(str)\n",
        "    X.loc[:, 'cb_person_default_on_file'] = X['cb_person_default_on_file'].astype(str)\n",
        "\n",
        "\n",
        "    columns_categ = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
        "\n",
        "    OHE_person_home_ownership = pd.get_dummies(X['person_home_ownership'], prefix='person_home_ownership', drop_first=False).astype(int)\n",
        "    OHE_loan_intent = pd.get_dummies(X['loan_intent'], prefix='loan_intent', drop_first=False).astype(int)\n",
        "    OHE_loan_grade = pd.get_dummies(X['loan_grade'], prefix='loan_grade', drop_first=False).astype(int)\n",
        "    OHE_cb_person_default_on_file = pd.get_dummies(X['cb_person_default_on_file'], prefix='cb_person_default_on_file', drop_first=False).astype(int)\n",
        "\n",
        "    columns_all = X.columns.tolist()\n",
        "    columns_exclude = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'loan_status']\n",
        "\n",
        "    # Get all the numerical variable names\n",
        "    columns_numerical = [column for column in columns_all if column not in columns_exclude]\n",
        "\n",
        "    # Concatenate the one-hot-encoding columns and numerical columns as the input data\n",
        "    X_input = pd.concat([OHE_person_home_ownership, OHE_loan_intent, OHE_loan_grade, OHE_cb_person_default_on_file, X[columns_numerical]], axis=1)\n",
        "\n",
        "    return X_input\n",
        "\n",
        "\n",
        "\n",
        "def over_sampling(X_train, y_train):\n",
        "  sm = SMOTE(random_state=33)\n",
        "  X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "  return X_res, y_res\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    data = load_data('credit_risk_dataset.csv')\n",
        "\n",
        "    feature_names = ['person_emp_length', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length', 'person_home_ownership', 'loan_intent' ,'loan_grade', 'cb_person_default_on_file']\n",
        "\n",
        "    X_scaled, y, scaler = preprocess_data(data,  feature_names)\n",
        "\n",
        "    #vif = calc_vif(data[feature_names]).sort_values(by = 'VIF', ascending = False)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(y_train.value_counts())\n",
        "\n",
        "\n",
        "    # X_train, y_train = over_sampling(X_train, y_train)\n",
        "\n",
        "    # print(y_res.value_counts())\n",
        "\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    y_pred_proba, y_pred = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    plot_precision_recall_curve(y_test, y_pred_proba)\n",
        "    plot_roc_curve(y_test, y_pred_proba)\n",
        "    plot_calibration_curve(y_test, y_pred_proba)\n",
        "    plot_lift_chart(y_test, y_pred_proba)\n",
        "\n",
        "\n",
        "\n",
        "    #sensitivity_analysis(model, data, scaler, feature_names)\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "    print('Model saved as logistic_regression_model.pkl')\n"
      ],
      "metadata": {
        "id": "Sp--fFPZkcfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}